{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NFL PLAY PREDICTION\n",
    "# --------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "### Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Importing the libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import time\n",
    "\n",
    "#ignore warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#Import and Clean Data\n",
    "data_df = pd.read_csv(\"nfl_data.csv\")\n",
    "\n",
    "#From the Original Dataset\n",
    "temp_cols = [\"passer_player_name\", \"rusher_player_name\"]\n",
    "columns_to_encode = [\"home_team\", \"away_team\", \"side_of_field\", \"defteam\", \"game_half\"]\n",
    "\n",
    "columns_to_keep = [\"posteam\", \"ydstogo\", \"down\", \"game_seconds_remaining\", \"season\", \"qtr\", \"drive\",\n",
    "                    \"yardline_100\", \"goal_to_go\", \"ydsnet\", \"posteam_timeouts_remaining\",\n",
    "                    \"defteam_timeouts_remaining\", \"posteam_score\", \"defteam_score\", \"score_differential\", \n",
    "                    \"home_wp\", \"away_wp\", \"fg_prob\", \"td_prob\", \"shotgun\", \"no_huddle\", \"wp\", \"def_wp\",\n",
    "                    \"quarter_seconds_remaining\"]\n",
    "\n",
    "target = [\"play_type\"]\n",
    "\n",
    "df = data_df[columns_to_keep+columns_to_encode+target]\n",
    "temp_df = data_df[temp_cols]\n",
    "data_df = df[(df[\"play_type\"] == \"run\") | (df[\"play_type\"] == \"pass\")]\n",
    "data_df = data_df[data_df['down'].notnull()]\n",
    "data_df = data_df[data_df['game_seconds_remaining'].notnull()]\n",
    "data_df = data_df[data_df['home_wp'].notnull()]\n",
    "data_df = data_df[data_df['away_wp'].notnull()]\n",
    "data_df = data_df[data_df['quarter_seconds_remaining'].notnull()]\n",
    "\n",
    "## DATA ENHANCEMENTS ##\n",
    "\n",
    "#is the possessing team playing at home?\n",
    "data_df['posteam_home'] = data_df['posteam'] == data_df['home_team']\n",
    "\n",
    "## PREVIOUS PLAY INFO ##\n",
    "#what was the outcome of previous plays (run or pass)?\n",
    "data_df['one_play_ago_type'] = data_df['play_type'].shift()\n",
    "data_df['two_plays_ago_type'] = data_df['play_type'].shift(2)\n",
    "\n",
    "#were the previous plays by the same team?\n",
    "data_df['one_play_ago_pos_same_team'] = data_df['posteam'].shift() == data_df['posteam']\n",
    "data_df['two_plays_ago_pos_same_team'] = data_df['posteam'].shift(2) == data_df['posteam']\n",
    "\n",
    "#was the previous passer likely to throw instead of running the ball?\n",
    "data_df['prev_pocket_passer'] = temp_df['passer_player_name'].shift().isin(['M.Ryan', 'A.Rodgers', \n",
    "                                                'T.Brady', 'P.Rivers', 'D.Brees', 'M.Stafford', \n",
    "                                                'J.Flacco', 'P.Manning', 'T.Romo', 'K.Cousins'])\n",
    "\n",
    "#was the previous passer likely to run instead of throwing the ball?\n",
    "data_df['prev_rush_passer'] = temp_df['passer_player_name'].shift().isin(['C.Newton', 'L.Jackson', \n",
    "                                                'D.Watson', 'D.Prescott', 'R.Wilson', 'T.Taylor', \n",
    "                                                'R.Griffin', 'M.Vick'])\n",
    "\n",
    "data_df['prev_top_rusher'] = temp_df['rusher_player_name'].shift().isin(['E.Elliott', 'S.Barkley', \n",
    "                                                'D.Johnson', 'T.Gurley', 'A.Peterson', 'L.Bell', \n",
    "                                                'L.Mccoy', 'M.Gordon', 'K.Hunt', 'D.Murray', \n",
    "                                                'D.Martin', 'R.Rice', 'C.Johnson', 'M.Turner'])\n",
    "\n",
    "# back-up rushers: 'J.Conner', 'M.Lynch'\n",
    "\n",
    "#data_df.describe\n",
    "# show what our data looks like: use data_df.describe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/logan/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py:390: DeprecationWarning: The 'categorical_features' keyword is deprecated in version 0.20 and will be removed in 0.22. You can use the ColumnTransformer instead.\n",
      "  \"use the ColumnTransformer instead.\", DeprecationWarning)\n",
      "/Users/logan/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py:390: DeprecationWarning: The 'categorical_features' keyword is deprecated in version 0.20 and will be removed in 0.22. You can use the ColumnTransformer instead.\n",
      "  \"use the ColumnTransformer instead.\", DeprecationWarning)\n",
      "/Users/logan/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py:390: DeprecationWarning: The 'categorical_features' keyword is deprecated in version 0.20 and will be removed in 0.22. You can use the ColumnTransformer instead.\n",
      "  \"use the ColumnTransformer instead.\", DeprecationWarning)\n",
      "/Users/logan/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py:390: DeprecationWarning: The 'categorical_features' keyword is deprecated in version 0.20 and will be removed in 0.22. You can use the ColumnTransformer instead.\n",
      "  \"use the ColumnTransformer instead.\", DeprecationWarning)\n",
      "/Users/logan/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py:390: DeprecationWarning: The 'categorical_features' keyword is deprecated in version 0.20 and will be removed in 0.22. You can use the ColumnTransformer instead.\n",
      "  \"use the ColumnTransformer instead.\", DeprecationWarning)\n",
      "/Users/logan/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py:390: DeprecationWarning: The 'categorical_features' keyword is deprecated in version 0.20 and will be removed in 0.22. You can use the ColumnTransformer instead.\n",
      "  \"use the ColumnTransformer instead.\", DeprecationWarning)\n",
      "/Users/logan/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py:390: DeprecationWarning: The 'categorical_features' keyword is deprecated in version 0.20 and will be removed in 0.22. You can use the ColumnTransformer instead.\n",
      "  \"use the ColumnTransformer instead.\", DeprecationWarning)\n",
      "/Users/logan/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py:390: DeprecationWarning: The 'categorical_features' keyword is deprecated in version 0.20 and will be removed in 0.22. You can use the ColumnTransformer instead.\n",
      "  \"use the ColumnTransformer instead.\", DeprecationWarning)\n",
      "/Users/logan/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py:390: DeprecationWarning: The 'categorical_features' keyword is deprecated in version 0.20 and will be removed in 0.22. You can use the ColumnTransformer instead.\n",
      "  \"use the ColumnTransformer instead.\", DeprecationWarning)\n",
      "/Users/logan/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py:390: DeprecationWarning: The 'categorical_features' keyword is deprecated in version 0.20 and will be removed in 0.22. You can use the ColumnTransformer instead.\n",
      "  \"use the ColumnTransformer instead.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "'''SideofField OHE'''\n",
    "#Encode and One Hot Encode SideofField\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "labelencoder_SOF = LabelEncoder()\n",
    "data_df[\"side_of_field\"] = labelencoder_SOF.fit_transform(data_df[\"side_of_field\"].astype(str))\n",
    "onehotencoder_SOF = OneHotEncoder(categorical_features=[0], sparse=False)\n",
    "SideofField_OHE = onehotencoder_SOF.fit_transform(data_df[\"side_of_field\"].values.reshape(-1,1))\n",
    "data_df = data_df.drop(columns = [\"side_of_field\"])\n",
    "\n",
    "'''posteam OHE'''\n",
    "#Encode and One Hot Encode postteam\n",
    "labelencoder_posteam = LabelEncoder()\n",
    "data_df[\"posteam\"] = labelencoder_posteam.fit_transform(data_df[\"posteam\"].astype(str))\n",
    "onehotencoder_posteam = OneHotEncoder(categorical_features=[0], sparse=False)\n",
    "posteam_OHE = onehotencoder_posteam.fit_transform(data_df[\"posteam\"].values.reshape(-1,1))\n",
    "data_df = data_df.drop(columns = [\"posteam\"])\n",
    "\n",
    "'''DefensiveTeam OHE'''\n",
    "#Encode and One Hot Encode DefensiveTeam\n",
    "labelencoder_defteam = LabelEncoder()\n",
    "data_df[\"defteam\"] = labelencoder_defteam.fit_transform(data_df[\"defteam\"].astype(str))\n",
    "onehotencoder_defteam = OneHotEncoder(categorical_features=[0], sparse=False)\n",
    "defteam_OHE = onehotencoder_defteam.fit_transform(data_df[\"defteam\"].values.reshape(-1,1))\n",
    "data_df = data_df.drop(columns = [\"defteam\"])\n",
    "\n",
    "'''AwayTeam OHE'''\n",
    "#Encode and One Hot Encode AwayTeam\n",
    "labelencoder_awayteam = LabelEncoder()\n",
    "data_df[\"away_team\"] = labelencoder_awayteam.fit_transform(data_df[\"away_team\"].astype(str))\n",
    "onehotencoder_awayteam = OneHotEncoder(categorical_features=[0], sparse=False)\n",
    "awayteam_OHE = onehotencoder_awayteam.fit_transform(data_df[\"away_team\"].values.reshape(-1,1))\n",
    "data_df = data_df.drop(columns = [\"away_team\"])\n",
    "\n",
    "'''HomeTeam OHE'''\n",
    "#Encode and One Hot Encode HomeTeam\n",
    "labelencoder_hometeam = LabelEncoder()\n",
    "data_df[\"home_team\"] = labelencoder_hometeam.fit_transform(data_df[\"home_team\"].astype(str))\n",
    "onehotencoder_hometeam = OneHotEncoder(categorical_features=[0], sparse=False)\n",
    "hometeam_OHE = onehotencoder_hometeam.fit_transform(data_df[\"home_team\"].values.reshape(-1,1))\n",
    "data_df = data_df.drop(columns = [\"home_team\"])\n",
    "\n",
    "'''game_half OHE'''\n",
    "#Encode and One Hot Encode game_half\n",
    "labelencoder_gamehalf = LabelEncoder()\n",
    "data_df[\"game_half\"] = labelencoder_gamehalf.fit_transform(data_df[\"game_half\"].astype(str))\n",
    "onehotencoder_gamehalf = OneHotEncoder(categorical_features=[0], sparse=False)\n",
    "gamehalf_OHE = onehotencoder_gamehalf.fit_transform(data_df[\"game_half\"].values.reshape(-1,1))\n",
    "data_df = data_df.drop(columns = [\"game_half\"])\n",
    "\n",
    "'''one_play_ago_type OHE'''\n",
    "#Encode and One Hot Encode one_play_ago_type\n",
    "labelencoder_oneplayagotype = LabelEncoder()\n",
    "data_df[\"one_play_ago_type\"] = labelencoder_oneplayagotype.fit_transform(data_df[\"one_play_ago_type\"].astype(str))\n",
    "onehotencoder_oneplayagotype = OneHotEncoder(categorical_features=[0], sparse=False)\n",
    "oneplayagotype_OHE = onehotencoder_oneplayagotype.fit_transform(data_df[\"one_play_ago_type\"].values.reshape(-1,1))\n",
    "data_df = data_df.drop(columns = [\"one_play_ago_type\"])\n",
    "\n",
    "'''one_play_ago_pos_same_team OHE'''\n",
    "#Encode and One Hot Encode one_play_ago_pos_same_team\n",
    "labelencoder_oneplayagopossameteam = LabelEncoder()\n",
    "data_df[\"one_play_ago_pos_same_team\"] = labelencoder_oneplayagopossameteam.fit_transform(data_df[\"one_play_ago_pos_same_team\"].astype(str))\n",
    "onehotencoder_oneplayagopossameteam = OneHotEncoder(categorical_features=[0], sparse=False)\n",
    "oneplayagopossameteam_OHE = onehotencoder_oneplayagopossameteam.fit_transform(data_df[\"one_play_ago_pos_same_team\"].values.reshape(-1,1))\n",
    "data_df = data_df.drop(columns = [\"one_play_ago_pos_same_team\"])\n",
    "\n",
    "'''two_plays_ago_type OHE'''\n",
    "#Encode and One Hot Encode two_plays_ago_type\n",
    "labelencoder_twoplaysagotype = LabelEncoder()\n",
    "data_df[\"two_plays_ago_type\"] = labelencoder_twoplaysagotype.fit_transform(data_df[\"two_plays_ago_type\"].astype(str))\n",
    "onehotencoder_twoplaysagotype = OneHotEncoder(categorical_features=[0], sparse=False)\n",
    "twoplaysagotype_OHE = onehotencoder_twoplaysagotype.fit_transform(data_df[\"two_plays_ago_type\"].values.reshape(-1,1))\n",
    "data_df = data_df.drop(columns = [\"two_plays_ago_type\"])\n",
    "\n",
    "'''two_plays_ago_pos_same_team OHE'''\n",
    "#Encode and One Hot Encode two_plays_ago_pos_same_team\n",
    "labelencoder_twoplaysagopossameteam = LabelEncoder()\n",
    "data_df[\"two_plays_ago_pos_same_team\"] = labelencoder_twoplaysagopossameteam.fit_transform(data_df[\"two_plays_ago_pos_same_team\"].astype(str))\n",
    "onehotencoder_twoplaysagopossameteam = OneHotEncoder(categorical_features=[0], sparse=False)\n",
    "twoplaysagopossameteam_OHE = onehotencoder_twoplaysagopossameteam.fit_transform(data_df[\"two_plays_ago_pos_same_team\"].values.reshape(-1,1))\n",
    "data_df = data_df.drop(columns = [\"two_plays_ago_pos_same_team\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Re-assemble the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Concatenate all the one hot encodings\n",
    "OHE_matrix = np.concatenate((SideofField_OHE, posteam_OHE, defteam_OHE, awayteam_OHE, \n",
    "                             hometeam_OHE, gamehalf_OHE, oneplayagotype_OHE,\n",
    "                             oneplayagopossameteam_OHE, twoplaysagotype_OHE,\n",
    "                             twoplaysagopossameteam_OHE), axis=1)\n",
    "\n",
    "#Rearrange the columns so Playtype is the last column\n",
    "cols = [\"ydstogo\", \"down\", \"game_seconds_remaining\", \"season\", \"qtr\", \"drive\", \"yardline_100\",\n",
    "        \"goal_to_go\", \"ydsnet\", \"posteam_timeouts_remaining\", \"defteam_timeouts_remaining\",\n",
    "        \"posteam_score\", \"defteam_score\", \"score_differential\", \"home_wp\", \"away_wp\",\n",
    "        \"fg_prob\", \"td_prob\", \"shotgun\", \"no_huddle\", \"wp\", \"def_wp\", \"quarter_seconds_remaining\",\n",
    "        \"posteam_home\", \"prev_pocket_passer\", \"prev_top_rusher\",\n",
    "        \"play_type\"]\n",
    "\n",
    "data_df = data_df[cols]\n",
    "\n",
    "X = data_df.iloc[:,:-1].values\n",
    "y = data_df.iloc[:,-1].values\n",
    "\n",
    "#Concatenate One hot encoded variables with X\n",
    "X = np.concatenate((X,OHE_matrix), axis=1)\n",
    "\n",
    "\n",
    "#Splitting the data into Training Set and Test Set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test= train_test_split(X,y,test_size=0.3,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#K-Fold Cross Validation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "def getModelAccuracies(classifierObj): \n",
    "    modelAccuracies = cross_val_score(estimator=classifierObj, X=X_train, y=y_train, cv=10)\n",
    "    return {\"score\": {\"mean\": modelAccuracies.mean(), \"std\": modelAccuracies.std()}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Normalizing the features\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "sc_X = StandardScaler()\n",
    "X_train_norm = sc_X.fit_transform(X_train)\n",
    "X_test_norm = sc_X.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning Models\n",
    "# -------------------------------\n",
    "\n",
    "\n",
    "### Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': {'mean': 0.7150366395911079, 'std': 0.0015638080808045866}}\n",
      "Time to run Logistic Regression: 153.2670919895172\n"
     ]
    }
   ],
   "source": [
    "#Fitting Logistic Regression to Training Set\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "log_start_time = time.time()\n",
    "\n",
    "classifierObj= LogisticRegression(random_state=0)\n",
    "classifierObj.fit(X_train, y_train)\n",
    "\n",
    "#Making predictions on the Test Set\n",
    "y_pred= classifierObj.predict(X_test)\n",
    "\n",
    "#Evaluating the predictions using a Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm_logistic = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "#Get model k-fold validated scores\n",
    "print(getModelAccuracies(classifierObj))\n",
    "log_end_time = time.time()\n",
    "print(\"Time to run Logistic Regression: \" + str(log_end_time - log_start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Naive Bayes Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': {'mean': 0.6165668497160193, 'std': 0.004173581116792475}}\n",
      "Time to run Naive Bayes: 59.67180609703064\n"
     ]
    }
   ],
   "source": [
    "#Fitting Classifier to Training Set. Create a classifier object here and call it classifierObj\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "nb_start_time = time.time()\n",
    "classifierObj = GaussianNB()\n",
    "classifierObj.fit(X_train, y_train)\n",
    "\n",
    "#Making predictions on the Test Set\n",
    "y_pred = classifierObj.predict(X_test)\n",
    "\n",
    "#Evaluating the predictions using a Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm_nb = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "#Get model k-fold validated scores\n",
    "print(getModelAccuracies(classifierObj))\n",
    "nb_end_time = time.time()\n",
    "print(\"Time to run Naive Bayes: \" + str(nb_end_time - nb_start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': {'mean': 0.6704839496581917, 'std': 0.0028634609856156177}}\n",
      "Time to run Decision Tree: 348.4114902019501\n"
     ]
    }
   ],
   "source": [
    "#Fitting Classifier to Training Set. Create a classifier object here and call it classifierObj\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dt_start_time = time.time()\n",
    "classifierObj = DecisionTreeClassifier(criterion='entropy')\n",
    "classifierObj.fit(X_train,y_train)\n",
    "\n",
    "#Making predictions on the Test Set\n",
    "y_pred = classifierObj.predict(X_test)\n",
    "\n",
    "#Evaluating the prediction using a Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm_dt = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "#Get model k-fold validated scores\n",
    "print(getModelAccuracies(classifierObj))\n",
    "dt_end_time = time.time()\n",
    "print(\"Time to run Decision Tree: \" + str(dt_end_time - dt_start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': {'mean': 0.7342641499857095, 'std': 0.0016660626276984694}}\n",
      "Time to run Random Forest: 509.4532377719879\n"
     ]
    }
   ],
   "source": [
    "#Fitting Classifier to Training Set. Create a classifier object here and call it classifierObj\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf_start_time = time.time()\n",
    "classifierObj = RandomForestClassifier(criterion='entropy', n_estimators=29)\n",
    "classifierObj.fit(X_train,y_train)\n",
    "\n",
    "#Making predictions on the Test Set\n",
    "y_pred = classifierObj.predict(X_test)\n",
    "\n",
    "#Evaluating the predictions using a Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm_rf = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "#Get model k-fold validated scores\n",
    "print(getModelAccuracies(classifierObj))\n",
    "rf_end_time = time.time()\n",
    "print(\"Time to run Random Forest: \" + str(rf_end_time - rf_start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Commented out due to processing time and low accuracy\n",
    "\n",
    "# #Normalizing the features\n",
    "# from sklearn.preprocessing import StandardScaler \n",
    "# sc_X = StandardScaler()\n",
    "# X_train_norm = sc_X.fit_transform(X_train)\n",
    "# X_test_norm = sc_X.transform(X_test)\n",
    "\n",
    "# #Fitting Classifier to Training Set. Create a classifier object here and call it classifierObj \n",
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "# knn_start_time = time.time()\n",
    "# classifierObj = KNeighborsClassifier(n_neighbors=5, p=2, metric='minkowski')\n",
    "# classifierObj.fit(X_train_norm, y_train)\n",
    "\n",
    "# #Making predictions on the Test Set\n",
    "# y_pred = classifierObj.predict(X_test_norm)\n",
    "# knn_end_time = time.time()\n",
    "# #Evaluating the predictions using a Confusion Matrix\n",
    "# from sklearn.metrics import confusion_matrix\n",
    "# cm_knn = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# knn_score = classifierObj.score(X_test_norm, y_test)\n",
    "# print(\"Score:\" + str(knn_score))\n",
    "# print(\"Time to run KNN: \" + str(knn_end_time - knn_start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kernel SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Commented out due to processing time and low accuracy\n",
    "\n",
    "# from sklearn.svm import SVC\n",
    "# ksvm_start_time = time.time()\n",
    "# classifierObj = SVC(kernel='rbf')\n",
    "# classifierObj.fit(X_train_norm, y_train)\n",
    "\n",
    "# #Making predictions on the Test Set \n",
    "# y_pred = classifierObj.predict(X_test_norm)\n",
    "\n",
    "# #Evaluating the predictions using a Confusion Matrix \n",
    "# from sklearn.metrics import confusion_matrix\n",
    "# cm_svm = confusion_matrix(y_test, y_pred)\n",
    "# ksvm_end_time = time.time()\n",
    "\n",
    "# #Get model svm validated scores\n",
    "# ksvm_score = classifierObj.score(X_test_norm, y_test)\n",
    "# print(\"Score: \" + str(ksvm_score))\n",
    "# print(\"Time to run KSVM: \" + str(ksvm_end_time - ksvm_start_time))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
